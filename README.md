# Chatbot---Using-LSTM (UNI and BI directional) & GRU ( UNI and BI directional )
Learning different models of building the chatbot using LSTM and GRU with different hyperparameters

DATASET : cornel movie dialog corpus is our dataset and we have used 5000 dialogs as there are memory constraints with the COLAB PRO.

I suggest to use with COLAB PRO + for higher datasets to avoid any gpu memory issues.

For execution please subscribe colab pro+ and just run the code in the jupyter note book. For training all the models it takes minimum of 4 hours.

Results :

1. Bidirectional LSTM outperforms other models in terms of accuracy and we trained our inference model on bi-directional lstm as we get better results insights while training the model. 
2. We applied softmax activation function to calculate the output layer.


Next Steps:

1. More training and Testing experiments are needed for better insights with corresponding to the different batch sizes.
2. Using of LSTM - ATTENTION mechanism model to derive best prediction results in our next work.
3. Using of other activation functions to derive best possible accuracies.
4. By taking more data we can test our model if it is accuracte enough to predict the question and respond to the user.


-------------------------****************************-----------------------------------------------------------------------------------
